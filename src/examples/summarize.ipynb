{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "\n",
    "Large language models are adept at summarizing due to their sophisticated understanding of language structure, semantics, and context derived from the vast amounts of text they have been trained on. They analyze and comprehend the core elements and main ideas within a text, enabling them to distill complex and lengthy content into succinct summaries. Summaries produced by language models help users quickly grasp the essential points of voluminous texts, facilitating more efficient decision-making and knowledge acquisition without the necessity to delve into and navigate through exhaustive details.\n",
    "\n",
    "To start, we first need to instantiate an Aleph Alpha `Client` so that we can make calls to the Aleph Alpha API, which we use to get access to the Aleph Alpha family of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "\n",
    "from intelligence_layer.connectors.limited_concurrency_client import LimitedConcurrencyClient\n",
    "\n",
    "client = LimitedConcurrencyClient.from_token(getenv(\"AA_TOKEN\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start building a simple summarization workflow.\n",
    "For starters, let's import a ready-to-go summarization method.\n",
    "\n",
    "This particular summarization method is optimized for handling extensive text inputs and producing summaries with a medium level of compression.\n",
    "Designed to maintain a balance between brevity and comprehensive detail, this method efficiently distills long-context information into concise summaries without omitting crucial content.\n",
    "\n",
    "Note, how the task takes a client instance, as we will be making calls to the Aleph Alpha API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.use_cases.summarize.long_context_medium_compression_summarize import LongContextMediumCompressionSummarize\n",
    "\n",
    "summarize_task = LongContextMediumCompressionSummarize(client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's find some longer text to summarize.\n",
    "\n",
    "Lately, I've been into wooden scyscrapers, so let's hit up Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.use_cases.summarize.summarize import LongContextSummarizeInput\n",
    "\n",
    "text = \"\"\"Plyscraper\n",
    "\n",
    "A plyscraper, or timber tower is a skyscraper made (at least partly) of wood. They may alternatively be known as mass timber buildings.\n",
    "\n",
    "There are four main types of engineered wood used for mass timber including cross-laminated timber (CLT), glued laminated timber (glulam), laminated strand lumber (LSL), and laminated veneer lumber (LVL). Of these three wood systems, CLT is the most commonly used.[1]\n",
    "\n",
    "When other materials, such as concrete or steel, are used in conjunction with engineered wood, these plyscrapers are called “hybrids”. For hybrid buildings, there are some approaches to how different materials can be used including the “Cree’s System” which was developed by Cree Buildings, and the “Finding the Forest Through the Trees\" (FFTT) construction model” developed by Michael Green. Cree's System combines the use of concrete and wood mainly in its hybrid flooring systems. In some instances, concrete can also be used as a core or for the foundation of a building because wood is too light. The FFTT construction model incorporates a wooden core and wooden floor slabs mixed with steel beams to provide ductility to the building.[1][2]\n",
    "\n",
    "When considering which engineered wood system to use for a plyscraper the individual benefits of each must be compared. CLT has a high fire resistance due to the fire-resistant adhesive used and the surface char layer that forms when it is exposed to fire. The surface char layer protects the interior of the wood from further damage. Glulam is typically used for columns and beams as an alternative to commonly used steel and concrete.[1][3] This is because it has a greater tensile strength-to-weight ratio than steel and can resist compression better than concrete.  LVL also has the same strength as concrete.[4]  As plyscrapers are made from wood, they sequester carbon during construction and are renewable if the forests that they are sourced from are sustainably managed.[1][3]\n",
    "\n",
    "Despite these benefits, there are bound to be some drawbacks when using the various engineered woods.  Steel overall has a greater strength and durability for the same sized profile when compared to its wood counterpart.[5] Thus, a building made with steel beams would require smaller beams than the same building constructed with wooden beams.  Walls and columns in the interior spaces of these plyscrapers can get so thick that the size of said interior space gets heavily reduced. This issue however, does not occur within shorter buildings.\"\"\"\n",
    "summarize_input = LongContextSummarizeInput(text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help developers and users alike understand how LLM-based applications work, we offer so-called `Tracer`s.\n",
    "They can be inserted into any task run and automatically log all underlying processes to enable easier debugging and auditability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelligence_layer.core.tracer import InMemoryTracer\n",
    "\n",
    "tracer = InMemoryTracer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's give our `summarize_input` and `tracer` to our `summarize_task` and run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Pretty\n",
    "\n",
    "\n",
    "output = summarize_task.run(summarize_input, tracer)\n",
    "Pretty(\" \".join(partial_summary.summary for partial_summary in output.partial_summaries))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's have a look at what our tracer picked up along the way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, how the task is broken up into subtasks, such as `ChunkTask` and `SingleChunkFewShotSummarize`.\n",
    "To work with longer texts, we break them up into smaller sections (\"chunks\") and each is summarized in turn.\n",
    "\n",
    "Congrats, you now know how a `Task` works and what a `Tracer` is!\n",
    "In the next notebooks, we'll dive into more detail on other tasks, as well as how to build your own and how to evaluate methodologies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10-intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
