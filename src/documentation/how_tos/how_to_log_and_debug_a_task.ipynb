{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from uuid import uuid4\n",
    "\n",
    "from aleph_alpha_client import Prompt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from intelligence_layer.connectors import StudioClient\n",
    "from intelligence_layer.core import (\n",
    "    CompleteInput,\n",
    "    InMemoryTracer,\n",
    "    LuminousControlModel,\n",
    "    Task,\n",
    "    TaskSpan,\n",
    ")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to log and debug a task\n",
    "The Intelligence Layer offers logging and debugging via a `Tracer`.  \n",
    "Here are several steps you can use to debug tasks with the trace feature:\n",
    "\n",
    "-----\n",
    "Most logging of a task (input, output, time) is done simply by inheriting from `Task`. This logs to a trace.\n",
    "\n",
    " - If you don't care about logging and tracing, use the `NoOpTracer`.\n",
    " - To create custom logging messages in a trace use `task_span.log()`.\n",
    " - To map a complex execution flow of a task into a single trace, pass the `task_span` of the `do_run` to other execution methods (e.g. `Task.run()` or `model.complete()`). \n",
    "   - If the execution method is not provided by the intelligence layer, the tracing of input and output has to happen manually. See the implementation of `Task.run()` for an example.\n",
    " - Use the [submit trace functionality of the `StudioClient`](./how_to_use_studio_with_traces.ipynb) to view and inspect a trace in Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTask(Task[str, str]):\n",
    "    def __init__(self, model: LuminousControlModel | None = None) -> None:\n",
    "        self._model = model if model else LuminousControlModel()\n",
    "\n",
    "    def do_run(self, input: str, task_span: TaskSpan) -> str:\n",
    "        should_output = random.random()\n",
    "        # log a custom message and value\n",
    "        task_span.log(\n",
    "            \"My very important log message that logs a random value\", should_output\n",
    "        )\n",
    "        if should_output > 0.5:\n",
    "            model_input = CompleteInput(prompt=Prompt.from_text(input), temperature=0.2)\n",
    "            # Create a trace tree by passing task_span to .run or .complete methods.\n",
    "            completion = self._model.complete(model_input, task_span)\n",
    "            return completion.completions[0].completion\n",
    "        else:\n",
    "            return \"Nope!\"\n",
    "\n",
    "\n",
    "tracer = InMemoryTracer()\n",
    "DummyTask().run(\"\", tracer)\n",
    "\n",
    "project_name = str(uuid4())\n",
    "studio_client = StudioClient(project=project_name)\n",
    "my_project = studio_client.create_project(project=project_name)\n",
    "\n",
    "submitted_trace_id = studio_client.submit_from_tracer(tracer)\n",
    "\n",
    "\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligence-layer-aL2cXmJM-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
