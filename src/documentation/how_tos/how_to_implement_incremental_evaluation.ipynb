{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T09:54:58.376698Z",
     "start_time": "2024-10-14T09:54:57.041090Z"
    }
   },
   "source": [
    "from documentation.how_tos.example_data import (\n",
    "    DummyAggregationLogic,\n",
    "    DummyEvaluation,\n",
    "    DummyExample,\n",
    "    example_data,\n",
    ")\n",
    "from intelligence_layer.evaluation import (\n",
    "    Aggregator,\n",
    "    Example,\n",
    "    IncrementalEvaluationLogic,\n",
    "    IncrementalEvaluator,\n",
    "    InMemoryAggregationRepository,\n",
    "    InMemoryEvaluationRepository,\n",
    "    SuccessfulExampleOutput,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to implement incremental evaluation\n",
    "This notebook outlines how to perform evaluations in an incremental fashion, i.e., adding additional runs to your existing evaluations without the need for recalculation.\n",
    "    \n",
    "## Step-by-Step Guide\n",
    "0. Run your tasks on the datasets on which you want to evaluate them (see [here](./how_to_run_a_task_on_a_dataset.ipynb))\n",
    "   - When evaluating multiple runs, all of them need the same data types \n",
    "1. Initialize all necessary repositories and define your `IncrementalEvaluationLogic`; It is similar to a normal `EvaluationLogic` (see [here](./how_to_implement_a_simple_evaluation_and_aggregation_logic.ipynb)) but you additionally have to implement your own `do_incremental_evaluate` method\n",
    "2. Initialize an `IncrementalEvaluator` with the repositories and your custom `IncrementalEvaluationLogic`\n",
    "3. Call the `evaluate_runs` method of the `IncrementalEvaluator`\n",
    "4. Aggregate your evaluations using the [standard aggregation](./how_to_aggregate_evaluations.ipynb) or using a [custom aggregation logic](./how_to_implement_a_simple_evaluation_and_aggregation_logic.ipynb)\n",
    "\n",
    "#### Steps for addition of new runs \n",
    "5. Call the `evaluate_additional_runs` method of the `IncrementalEvaluator`:\n",
    "   - `run_ids`: Runs to be included in the evaluation results, including those that have been evaluated before\n",
    "   - `previous_evaluation_ids`: Runs **not** to be re-evaluated, depending on the specific implementation of the `do_incremental_evaluate` method\n",
    "6. Aggregate all your `EvaluationOverview`s"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T09:54:58.400706Z",
     "start_time": "2024-10-14T09:54:58.380869Z"
    }
   },
   "source": [
    "# Step 0\n",
    "examples = [\n",
    "    DummyExample(input=\"input1\", expected_output=\"expected_output1\", data=\"data1\")\n",
    "]\n",
    "my_example_data = example_data()\n",
    "\n",
    "dataset_repository = my_example_data.dataset_repository\n",
    "run_repository = my_example_data.run_repository\n",
    "\n",
    "# Step 1\n",
    "evaluation_repository = InMemoryEvaluationRepository()\n",
    "aggregation_repository = InMemoryAggregationRepository()\n",
    "\n",
    "\n",
    "class DummyIncrementalEvaluationLogic(\n",
    "    IncrementalEvaluationLogic[str, str, str, DummyEvaluation]\n",
    "):\n",
    "    def do_incremental_evaluate(\n",
    "        self,\n",
    "        example: Example[str, str],\n",
    "        outputs: list[SuccessfulExampleOutput[str]],\n",
    "        already_evaluated_outputs: list[list[SuccessfulExampleOutput[str]]],\n",
    "    ) -> DummyEvaluation:\n",
    "        # Here we just return the dummy evaluation. In a real use case one could also use `already_evaluated_outputs' to skip previous evaluations,\n",
    "        return DummyEvaluation(eval=\"DummyEvalResult\")\n",
    "\n",
    "\n",
    "# Step 2\n",
    "incremental_evaluator = IncrementalEvaluator(\n",
    "    dataset_repository,\n",
    "    run_repository,\n",
    "    evaluation_repository,\n",
    "    \"My incremental evaluation\",\n",
    "    DummyIncrementalEvaluationLogic(),\n",
    ")\n",
    "\n",
    "# Step 3\n",
    "incremental_evaluator.evaluate_runs(my_example_data.run_overview_1.id)\n",
    "\n",
    "# Step 4\n",
    "aggregation_logic = DummyAggregationLogic()\n",
    "aggregator = Aggregator(\n",
    "    evaluation_repository, aggregation_repository, \"MyAggregator\", aggregation_logic\n",
    ")\n",
    "aggregation_overview = aggregator.aggregate_evaluation(\n",
    "    *evaluation_repository.evaluation_overview_ids()\n",
    ")\n",
    "print(aggregation_overview)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 2it [00:00, 54471.48it/s]\n",
      "Evaluating: 2it [00:00, 20068.44it/s]\n",
      "Evaluating: 2it [00:00, 64527.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation Overview ID = be8292b6-f53f-4161-8cdd-05c591ae38be\n",
      "Start time = 2024-10-14 09:54:58.399622+00:00\n",
      "End time = 2024-10-14 09:54:58.399644+00:00\n",
      "Successful example count = 2\n",
      "Count of examples crashed during evaluation = 0\n",
      "Description = \"MyAggregator\"\n",
      "Labels = set()\n",
      "Metadata = {}\n",
      "IDs of aggregated Evaluation Overviews = ['e0dc8b91-befd-4460-931d-c8e50b53bf17']\n",
      "IDs of aggregated Run Overviews = ['04a6d034-ab4b-4d99-808c-c757d2c0f99d']\n",
      "Statistics = {\n",
      "num_evaluations=2\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T11:13:20.654805Z",
     "start_time": "2024-10-14T10:59:58.048409Z"
    }
   },
   "source": [
    "## Addition of new task/run\n",
    "# Step 5\n",
    "run_ids = [my_example_data.run_overview_1.id, my_example_data.run_overview_2.id]\n",
    "incremental_evaluator.evaluate_additional_runs(\n",
    "    *run_ids,\n",
    "    previous_evaluation_ids=evaluation_repository.evaluation_overview_ids(),\n",
    ")\n",
    "\n",
    "# Step 6\n",
    "second_aggregation_overview = aggregator.aggregate_evaluation(\n",
    "    *evaluation_repository.evaluation_overview_ids()\n",
    ")\n",
    "print(second_aggregation_overview)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## Addition of new task/run\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Step 5\u001B[39;00m\n\u001B[1;32m      3\u001B[0m run_ids \u001B[38;5;241m=\u001B[39m [my_example_data\u001B[38;5;241m.\u001B[39mrun_overview_1\u001B[38;5;241m.\u001B[39mid, my_example_data\u001B[38;5;241m.\u001B[39mrun_overview_2\u001B[38;5;241m.\u001B[39mid]\n\u001B[0;32m----> 4\u001B[0m \u001B[43mincremental_evaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_additional_runs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrun_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprevious_evaluation_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluation_repository\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluation_overview_ids\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Step 6\u001B[39;00m\n\u001B[1;32m     10\u001B[0m second_aggregation_overview \u001B[38;5;241m=\u001B[39m aggregator\u001B[38;5;241m.\u001B[39maggregate_evaluation(\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;241m*\u001B[39mevaluation_repository\u001B[38;5;241m.\u001B[39mevaluation_overview_ids()\n\u001B[1;32m     12\u001B[0m )\n",
      "File \u001B[0;32m~/develop/intelligence-layer/src/intelligence_layer/evaluation/evaluation/evaluator/incremental_evaluator.py:173\u001B[0m, in \u001B[0;36mIncrementalEvaluator.evaluate_additional_runs\u001B[0;34m(self, previous_evaluation_ids, num_examples, abort_on_error, labels, metadata, *run_ids)\u001B[0m\n\u001B[1;32m    170\u001B[0m     previous_run_ids\u001B[38;5;241m.\u001B[39mappend(prev_run_ids)\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluation_logic\u001B[38;5;241m.\u001B[39mset_previous_run_output_ids(previous_run_ids)\n\u001B[0;32m--> 173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_runs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrun_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_examples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m    \u001B[49m\u001B[43mabort_on_error\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mabort_on_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/develop/intelligence-layer/src/intelligence_layer/evaluation/evaluation/evaluator/evaluator.py:145\u001B[0m, in \u001B[0;36mEvaluator.evaluate_runs\u001B[0;34m(self, num_examples, abort_on_error, skip_example_on_any_failure, description, labels, metadata, *run_ids)\u001B[0m\n\u001B[1;32m    140\u001B[0m eval_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evaluation_repository\u001B[38;5;241m.\u001B[39minitialize_evaluation()\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ThreadPoolExecutor(max_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m executor:\n\u001B[1;32m    143\u001B[0m     example_evaluations \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(  \u001B[38;5;66;03m# the list is needed to consume the iterator returned from the executor.map\u001B[39;00m\n\u001B[1;32m    144\u001B[0m         tqdm(\n\u001B[0;32m--> 145\u001B[0m             \u001B[43mexecutor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m                    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mabort_on_error\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_retrieve_eval_logic_input\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mrun_overviews\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mskip_example_on_any_failure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_example_on_any_failure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mnum_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_examples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    155\u001B[0m             desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    156\u001B[0m         )\n\u001B[1;32m    157\u001B[0m     )\n\u001B[1;32m    159\u001B[0m failed_evaluation_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(example_evaluation, FailedExampleEvaluation)\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m example_evaluation \u001B[38;5;129;01min\u001B[39;00m example_evaluations\n\u001B[1;32m    162\u001B[0m )\n\u001B[1;32m    164\u001B[0m successful_evaluation_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(example_evaluations) \u001B[38;5;241m-\u001B[39m failed_evaluation_count\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.8/lib/python3.11/concurrent/futures/_base.py:608\u001B[0m, in \u001B[0;36mExecutor.map\u001B[0;34m(self, fn, timeout, chunksize, *iterables)\u001B[0m\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    606\u001B[0m     end_time \u001B[38;5;241m=\u001B[39m timeout \u001B[38;5;241m+\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 608\u001B[0m fs \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43miterables\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001B[39;00m\n\u001B[1;32m    611\u001B[0m \u001B[38;5;66;03m# before the first iterator value is required.\u001B[39;00m\n\u001B[1;32m    612\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresult_iterator\u001B[39m():\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.8/lib/python3.11/concurrent/futures/_base.py:608\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    606\u001B[0m     end_time \u001B[38;5;241m=\u001B[39m timeout \u001B[38;5;241m+\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 608\u001B[0m fs \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43miterables\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[38;5;66;03m# Yield must be hidden in closure so that the futures are submitted\u001B[39;00m\n\u001B[1;32m    611\u001B[0m \u001B[38;5;66;03m# before the first iterator value is required.\u001B[39;00m\n\u001B[1;32m    612\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresult_iterator\u001B[39m():\n",
      "File \u001B[0;32m~/develop/intelligence-layer/src/intelligence_layer/evaluation/evaluation/evaluator/base_evaluator.py:277\u001B[0m, in \u001B[0;36mEvaluatorBase._generate_evaluation_inputs\u001B[0;34m(self, examples, example_outputs_for_example, skip_example_on_any_failure, num_examples)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_generate_evaluation_inputs\u001B[39m(\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    265\u001B[0m     examples: Iterable[Example[Input, ExpectedOutput]],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    273\u001B[0m     ]\n\u001B[1;32m    274\u001B[0m ]:\n\u001B[1;32m    275\u001B[0m     current_example \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 277\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_outputs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_outputs_for_example\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m    279\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43many\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m            \u001B[49m\u001B[43mexample\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mexample_output\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexample_id\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexample_output\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexample_outputs\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mraise\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;167;43;01mValueError\u001B[39;49;00m\u001B[43m(\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mThe ids of example and output do not match. Therefore, the evaluation cannot continue.\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m    286\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mexample id: \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mexample\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m, output id: \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mexample_outputs\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m    287\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/IntelliJIdea2024.2/plugins/python-ce/helpers/pydev/pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Application Support/JetBrains/IntelliJIdea2024.2/plugins/python-ce/helpers/pydev/pydevd.py:1235\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1235\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T09:54:58.620476Z",
     "start_time": "2024-10-14T09:54:58.618723Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
