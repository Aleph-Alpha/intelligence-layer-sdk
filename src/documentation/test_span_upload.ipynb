{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from intelligence_layer.core.tracer.tracer import (\n",
    "    Context,\n",
    "    Event,\n",
    "    ExportedSpan,\n",
    "    ExportedSpanList,\n",
    "    SpanAttributes,\n",
    "    SpanStatus,\n",
    "    TaskSpanAttributes,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_random_dict(max_key_value_length=1000, max_dict_size=5):\n",
    "    dict_size = random.randint(1, max_dict_size)\n",
    "    random_dict = {}\n",
    "    for _ in range(dict_size):\n",
    "        key_length = random.randint(1, max_key_value_length)\n",
    "        value_length = random.randint(1, max_key_value_length)\n",
    "        key = \"\".join(\n",
    "            random.choice(string.ascii_letters + string.digits)\n",
    "            for _ in range(key_length)\n",
    "        )\n",
    "        value = \"\".join(\n",
    "            random.choice(string.ascii_letters + string.digits)\n",
    "            for _ in range(value_length)\n",
    "        )\n",
    "        random_dict[key] = value\n",
    "    return random_dict\n",
    "\n",
    "\n",
    "def generate_exported_span_list(byte_size: int) -> ExportedSpanList:\n",
    "    exported_spans = []\n",
    "    current_size = 0\n",
    "    root_span = None\n",
    "\n",
    "    while current_size < byte_size:\n",
    "        if not root_span:\n",
    "            # Create the root span\n",
    "            root_span = ExportedSpan(\n",
    "                context=Context(trace_id=uuid.uuid4(), span_id=uuid.uuid4()),\n",
    "                name=\"root_span\",\n",
    "                parent_id=None,\n",
    "                start_time=datetime.utcnow() - timedelta(minutes=random.randint(0, 60)),\n",
    "                end_time=datetime.utcnow(),\n",
    "                attributes=random.choice(\n",
    "                    [\n",
    "                        SpanAttributes(),\n",
    "                        TaskSpanAttributes(\n",
    "                            input=generate_random_dict(), output=generate_random_dict()\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "                events=[\n",
    "                    Event(\n",
    "                        name=f\"event_{i}\",\n",
    "                        message=f\"message_{i}\",\n",
    "                        body=generate_random_dict(),\n",
    "                    )\n",
    "                    for i in range(random.randint(1, 10))\n",
    "                ],\n",
    "                status=random.choice([SpanStatus.OK, SpanStatus.ERROR]),\n",
    "            )\n",
    "            exported_spans.append(root_span)\n",
    "            current_size += len(root_span.json().encode(\"utf-8\"))\n",
    "        else:\n",
    "            # Create a child span\n",
    "            parent_span = random.choice(exported_spans)\n",
    "            child_span = ExportedSpan(\n",
    "                context=Context(\n",
    "                    trace_id=parent_span.context.trace_id, span_id=uuid.uuid4()\n",
    "                ),\n",
    "                name=f\"child_span_{len(exported_spans)}\",\n",
    "                parent_id=parent_span.context.span_id,\n",
    "                start_time=parent_span.start_time\n",
    "                + timedelta(milliseconds=random.randint(0, 1000)),\n",
    "                end_time=parent_span.end_time\n",
    "                + timedelta(milliseconds=random.randint(0, 1000)),\n",
    "                attributes=random.choice(\n",
    "                    [\n",
    "                        SpanAttributes(),\n",
    "                        TaskSpanAttributes(\n",
    "                            input=generate_random_dict(), output=generate_random_dict()\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "                events=[\n",
    "                    Event(\n",
    "                        name=f\"event_{i}\",\n",
    "                        message=f\"message_{i}\",\n",
    "                        body=generate_random_dict(),\n",
    "                    )\n",
    "                    for i in range(random.randint(1, 10))\n",
    "                ],\n",
    "                status=random.choice([SpanStatus.OK, SpanStatus.ERROR]),\n",
    "            )\n",
    "            exported_spans.append(child_span)\n",
    "            current_size += len(child_span.json().encode(\"utf-8\"))\n",
    "\n",
    "        # Avoid excessive memory usage\n",
    "        if len(exported_spans) > 1000:\n",
    "            break\n",
    "\n",
    "    return ExportedSpanList(root=exported_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(data):\n",
    "    size = len(data.model_dump_json().encode(\"utf-8\"))\n",
    "    print(size)\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from intelligence_layer.core.tracer.tracer import SpanType\n",
    "\n",
    "\n",
    "def _upload_trace(trace: ExportedSpanList, max_size=100) -> str:\n",
    "    MAX_TRACE_SIZE = 1_000_000  # 1MB\n",
    "    TRUNCATED_PLACEHOLDER = \"[TRUNCATED]\"\n",
    "\n",
    "    def slim_span(span: ExportedSpan) -> ExportedSpan:\n",
    "        \"\"\"Create a trimmed version of a span with reduced payload size.\"\"\"\n",
    "        span_data = span.model_dump()\n",
    "\n",
    "        # Trim attributes\n",
    "        if isinstance(span.attributes, TaskSpanAttributes):\n",
    "            span_data[\"attributes\"] = TaskSpanAttributes(\n",
    "                type=SpanType.TASK_SPAN,\n",
    "                input=_truncate_value(span.attributes.input),\n",
    "                output=_truncate_value(span.attributes.output),\n",
    "            )\n",
    "\n",
    "        # Trim events while keeping first/last for context\n",
    "        if span.events:\n",
    "            kept_events = (\n",
    "                [span.events[0], span.events[-1]]\n",
    "                if len(span.events) > 2\n",
    "                else span.events\n",
    "            )\n",
    "            span_data[\"events\"] = [\n",
    "                Event(\n",
    "                    name=event.name,\n",
    "                    message=_truncate_str(event.message, 200),\n",
    "                    body=_truncate_value(event.body),\n",
    "                    timestamp=event.timestamp,\n",
    "                )\n",
    "                for event in kept_events\n",
    "            ]\n",
    "\n",
    "        return ExportedSpan(**span_data)\n",
    "\n",
    "    def _truncate_value(value: Any, max_size: int = 1000) -> Any:\n",
    "        \"\"\"Recursively truncate large values while maintaining JSON serializability.\"\"\"\n",
    "        if isinstance(value, (str, bytes)):\n",
    "            return _truncate_str(value, max_size)\n",
    "        if isinstance(value, dict):\n",
    "            return {k: _truncate_value(v, max_size) for k, v in value.items()}\n",
    "        if isinstance(value, list):\n",
    "            return [\n",
    "                _truncate_value(v, max_size) for v in value[:10]\n",
    "            ]  # Keep first 10 elements\n",
    "        return value\n",
    "\n",
    "    def _truncate_str(value: str, max_length: int) -> str:\n",
    "        return (\n",
    "            value[:max_length] + TRUNCATED_PLACEHOLDER\n",
    "            if len(value) > max_length\n",
    "            else value\n",
    "        )\n",
    "\n",
    "    # Check initial size\n",
    "    if get_size(trace) > MAX_TRACE_SIZE:\n",
    "        # Find largest span using serialized size\n",
    "        spans = trace.root\n",
    "        largest_span = max(spans, key=lambda s: len(s.model_dump_json()))\n",
    "\n",
    "        # Replace largest span with trimmed version\n",
    "        modified_spans = [slim_span(s) if s == largest_span else s for s in spans]\n",
    "        trace = ExportedSpanList(root=modified_spans)\n",
    "\n",
    "    # Proceed with upload\n",
    "    print(\"final length:\", get_size(trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_exported_span_list(50_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_upload_trace(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_upload_trace()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
